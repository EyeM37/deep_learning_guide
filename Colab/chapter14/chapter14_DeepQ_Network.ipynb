{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URUsUnnjNQcK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import pickle as pic\n",
        "from collections import deque\n",
        "import sys\n",
        "\n",
        "loss_function = tf.keras.losses.Huber()\n",
        "initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFLa4rBPNdGz"
      },
      "outputs": [],
      "source": [
        "learning_rate=0.00025\n",
        "\n",
        "loss_function = tf.keras.losses.Huber()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDnpataINgxp"
      },
      "outputs": [],
      "source": [
        "def create_network(learning_rate, action_space):\t\n",
        "    initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.Input(shape=(105,80,4)))\n",
        "    model.add(tf.keras.layers.Conv2D(32, 8, padding=\"same\", strides=4, activation=\"relu\", kernel_initializer=initializer, use_bias=False, name = \"conv2d_1\"))\n",
        "    model.add(tf.keras.layers.Conv2D(64, 4, padding=\"same\", strides=2, activation=\"relu\", kernel_initializer=initializer, use_bias=False, name = \"conv2d_2\"))\n",
        "    model.add(tf.keras.layers.Conv2D(64, 3, padding=\"same\", strides=1, activation=\"relu\", kernel_initializer=initializer, use_bias=False, name = \"conv2d_3\"))\n",
        "    model.add(tf.keras.layers.Flatten(name = \"flatten_1\"))\n",
        "    model.add(tf.keras.layers.Dense(512,activation=\"relu\", kernel_initializer=initializer, name = \"dense_1\"))\n",
        "    model.add(tf.keras.layers.Dense(action_space, kernel_initializer=initializer, name = \"dense_2\"))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2CyvlzYNkWS"
      },
      "outputs": [],
      "source": [
        "Y!wget http://www.atarimania.com/roms/Roms.rar\n",
        "!mkdir ROM\n",
        "!unrar e Roms.rar ROM\n",
        "!python -m atari_py.import_roms ROM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_VH-vCUOvnJ"
      },
      "outputs": [],
      "source": [
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke9IoZpzNrjf"
      },
      "outputs": [],
      "source": [
        "env = gym.make('Pong-v0')\n",
        "\n",
        "model = create_network(learning_rate, env.action_space.n)\n",
        "model.compile(loss=loss_function, optimizer=optimizer)\n",
        "\n",
        "target_model = create_network(learning_rate, env.action_space.n)\n",
        "target_model.compile(loss=loss_function, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT5OeCbFN53r"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TaXTCsWO69U"
      },
      "outputs": [],
      "source": [
        "target_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD_pN_tFO_en"
      },
      "outputs": [],
      "source": [
        "env = gym.make('Pong-v0')\n",
        "env.reset()\n",
        "\n",
        "action = env.action_space.sample() \n",
        "state, reward, done, info = env.step(action)\n",
        "\n",
        "print(state.shape)\n",
        "print(state.min(), state.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It0Sxzu0PERA"
      },
      "outputs": [],
      "source": [
        "print(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA50d9zSPG4t"
      },
      "outputs": [],
      "source": [
        "mpl.rcParams['figure.dpi'] = 300\n",
        "\n",
        "plt.imshow(state)\n",
        "plt.savefig('pong.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ-0h97pPJfQ"
      },
      "outputs": [],
      "source": [
        "def screen_pixel_preprocess(observation):\n",
        "    s = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
        "    s = cv2.resize(s, (0, 0), fx=0.5, fy=0.5, interpolation = cv2.INTER_AREA) \n",
        "    s = s/236.0\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVjUdserPQyy"
      },
      "outputs": [],
      "source": [
        "state = screen_pixel_preprocess(state)\n",
        "state.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dH_qIwslPTev"
      },
      "outputs": [],
      "source": [
        "print(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eDnM94yPW99"
      },
      "outputs": [],
      "source": [
        "plt.imshow(state, cmap='gray')\n",
        "plt.savefig('pong2.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niy_L9dcPaYB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReiJ_g-UeISz"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"drive/My Drive/colabpro_drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMJHtj_HPgC3"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6TRDOpQQHpC"
      },
      "source": [
        "# Render OpenAI Gym on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZEzozqzP_dV"
      },
      "outputs": [],
      "source": [
        "!apt update\n",
        "!apt install xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SUiMNUEQPlP"
      },
      "outputs": [],
      "source": [
        "nb_path = \"/content/drive/My Drive/colabpro_drive/lib\"\n",
        "sys.path.append(nb_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJc75nSBQjlS"
      },
      "outputs": [],
      "source": [
        "!pip install pyvirtualdisplay --target=\"{nb_path}\" --upgrade "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyZYGLsCQ3QQ"
      },
      "outputs": [],
      "source": [
        "import pyvirtualdisplay\n",
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luvlXvhmRH5m"
      },
      "outputs": [],
      "source": [
        "d = pyvirtualdisplay.Display()\n",
        "d.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0gnauYxRQOL"
      },
      "outputs": [],
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay loop controls style=\"height: 400px;\">\n",
        "      <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "      </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb_s_dtcRbJ3"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make('Pong-v0'))\n",
        "state = env.reset()\n",
        "\n",
        "while True:\n",
        "    env.render()\n",
        "    action = env.action_space.sample() \n",
        "    state, reward, done, info = env.step(action) \n",
        "        \n",
        "    if done: \n",
        "        break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp344tjFSSbu"
      },
      "source": [
        "#Exploration Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_CtZPyXRf2U"
      },
      "outputs": [],
      "source": [
        "epsilon = 1.0\n",
        "epsilon_min = 0.1\n",
        "epsilon_max = 1.0\n",
        "epsilon_interval = (\n",
        "    epsilon_max - epsilon_min\n",
        ")\n",
        "\n",
        "epsilon_greedy_frames = 1000000.0\n",
        "epsilon_random_frames = 50000\n",
        "\n",
        "eps_memory = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxB0lnH9ScxH"
      },
      "outputs": [],
      "source": [
        "for frame_count in range(2000000):\n",
        "  if frame_count < epsilon_random_frames:\n",
        "    eps_memory.append(1)\n",
        "  else:  \n",
        "    eps_memory.append(epsilon)\n",
        "\n",
        "  epsilon -= epsilon_interval/epsilon_greedy_frames\n",
        "  epsilon = max(epsilon, epsilon_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLM1YNjwTGEZ"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objs as go\n",
        "import pickle as p\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9quOtLNSlw0"
      },
      "outputs": [],
      "source": [
        "h1 = go.Scatter(y=eps_memory, \n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='blue'),\n",
        "                    name=\"epsilon\"\n",
        "                   )\n",
        "\n",
        "data = [h1]\n",
        "layout1 = go.Layout(title='Epsilon Schedule',\n",
        "                   xaxis=dict(title='Frame Count'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "fig1.show(renderer=\"colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COXOrC1QT0mh"
      },
      "source": [
        "# Collect Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iui480SWSpNr"
      },
      "outputs": [],
      "source": [
        "frame_id = 0\n",
        "state = []\n",
        "pre_state = []\n",
        "\n",
        "def sample():\n",
        "  return np.random.choice(6)\n",
        "\n",
        "def step(action):\n",
        "  global frame_id\n",
        "  frame_id+=1\n",
        "  return frame_id\n",
        "\n",
        "def update_state(state, observation):\n",
        "    state.append(observation)\n",
        "\n",
        "    if len(state) > 4:\n",
        "        del state[:1]\n",
        "\n",
        "def predict(state):\n",
        "  return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtOo-zlGT-54"
      },
      "outputs": [],
      "source": [
        "update_state(state, None)\n",
        "\n",
        "for num_step in range(5):\n",
        "  if len(state) < 4:\n",
        "      action = sample()\n",
        "  else:\n",
        "      action = predict(state)\n",
        "\n",
        "  pre_state.append(state[-1])\n",
        "  if len(pre_state) > 4:\n",
        "      del pre_state[:1]\n",
        "  \n",
        "  observation = step(action)\n",
        "\n",
        "  update_state(state,observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqDYwbDvUKsP"
      },
      "outputs": [],
      "source": [
        "pre_state, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U3dWn9kVqyq"
      },
      "source": [
        "# **Double DQN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lXBdBlBVOxH"
      },
      "outputs": [],
      "source": [
        "def update_state(state, observation):\n",
        "    observation = screen_pixel_preprocess(observation)\n",
        "    state.append(observation)\n",
        "\n",
        "    if len(state) > 4:\n",
        "        del state[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXes9XCNVx-8"
      },
      "outputs": [],
      "source": [
        "def save_history(filename, history):\n",
        "    with open(filename, 'wb') as file:\n",
        "      pic.dump(history, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNj2w9UOV0YX"
      },
      "outputs": [],
      "source": [
        "action_memory = []\n",
        "state_memory = []\n",
        "state_next_memory = []\n",
        "rewards_memory = []\n",
        "done_memory = []\n",
        "history= []\n",
        "\n",
        "num_episode = 2000\n",
        "frame_count = 0\n",
        "\n",
        "epsilon_random_frames = 50000\n",
        "epsilon_greedy_frames = 1000000.0\n",
        "max_memory_length = 40000\n",
        "update_after_actions = 4\n",
        "update_target_network = 10000\n",
        "\n",
        "num_action = env.action_space.n\n",
        "batch_size = 32\n",
        "\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "epsilon = 1.0\n",
        "epsilon_min = 0.1\n",
        "epsilon_max = 1.0\n",
        "epsilon_interval = (\n",
        "    epsilon_max - epsilon_min\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ih2S8FbzV4sI"
      },
      "outputs": [],
      "source": [
        "for i in range(num_episode):\n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "    state = []\n",
        "    pre_state = []\n",
        "    update_state(state,observation)\n",
        "\n",
        "    episode_reward = 0\n",
        "\n",
        "    while not done: \n",
        "        frame_count += 1\n",
        "        if frame_count < epsilon_random_frames or epsilon > random.random() or len(state) < 4:  \n",
        "            action = np.random.choice(num_action)\n",
        "        else:\n",
        "            s = np.stack((state[0],state[1],state[2],state[3]),axis=2)\n",
        "            s = np.array([s])\n",
        "\n",
        "            action_probs = model.predict(s)\n",
        "            action = tf.argmax(action_probs[0]).numpy()\n",
        "\n",
        "        epsilon -= epsilon_interval/epsilon_greedy_frames\n",
        "        epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "        pre_state.append(state[-1])\n",
        "        if len(pre_state) > 4:\n",
        "            del pre_state[:1]\n",
        "\n",
        "        observation, reward, done, _ = env.step(action)\n",
        "\n",
        "        update_state(state, observation)\n",
        "\n",
        "\n",
        "        episode_reward += reward\n",
        "\n",
        "        if len(state) == 4 and len(pre_state) == 4:\n",
        "            action_memory.append(action)\n",
        "\n",
        "            pre_state_for_model = np.stack((pre_state[0],pre_state[1],pre_state[2],pre_state[3]),axis=2)\n",
        "            state_memory.append(pre_state_for_model)\n",
        "\n",
        "            state_for_model = np.stack((state[0],state[1],state[2],state[3]),axis=2)\n",
        "            state_next_memory.append(state_for_model)\n",
        "\n",
        "            rewards_memory.append(reward)\n",
        "        \n",
        "        if frame_count % update_after_actions == 0 and len(rewards_memory) > batch_size:\n",
        "            random_index = np.random.choice(range(len(rewards_memory)), size=batch_size)\n",
        "\n",
        "            action_sample = [action_memory[i] for i in random_index]\n",
        "            state_sample = np.array([state_memory[i] for i in random_index])\n",
        "            state_next_sample = np.array([state_next_memory[i] for i in random_index])\n",
        "            rewards_sample = [rewards_memory[i] for i in random_index]\n",
        "            \n",
        "            future_rewards = target_model.predict(state_next_sample)\n",
        "            next_q_values = rewards_sample + gamma * tf.reduce_max(\n",
        "                future_rewards, axis=1\n",
        "            )\n",
        "\n",
        "            masks = tf.one_hot(action_sample, num_action)\n",
        "            \n",
        "            with tf.GradientTape() as tape:\n",
        "                q_values = model(state_sample)\n",
        "                q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "\n",
        "                loss = loss_function(next_q_values, q_action)\n",
        "                grads = tape.gradient(loss, model.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        if frame_count % update_target_network == 0:\n",
        "            target_model.set_weights(model.get_weights())\n",
        "\n",
        "        if len(rewards_memory) > max_memory_length:\n",
        "            del action_memory[:1]\n",
        "            del state_memory[:1]\n",
        "            del state_next_memory[:1]\n",
        "            del rewards_memory[:1]    \n",
        "\n",
        "    history.append(episode_reward)        \n",
        "    print(str(i)+ \" episode total reward:\",episode_reward)\n",
        "    print(\"Frame Count = \" + str(frame_count))\n",
        "    \n",
        "    if i%100 == 0:\n",
        "        print(\"Saving the model\")\n",
        "        model.save(\"model/model-{}.h5\".format(i))\n",
        "        \n",
        "        print(\"Saving the history\")\n",
        "        save_history(\"reward_history\", history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iGak9HymV_R9"
      },
      "outputs": [],
      "source": [
        "# # หากต้องการ Run Colab โดยให้มีการรักษา Session ไว้ ท่านสามารถนำ Code ข้างล่างนี้ไปวางที่ JavaScript Console ของ Browser และสั่ง Run Script ได้ \n",
        "# function ConnectButton(){\n",
        "#     console.log(\"Connect pushed\"); \n",
        "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "# }\n",
        "# setInterval(ConnectButton,80000);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "PDL-14-DeepQ-Network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}