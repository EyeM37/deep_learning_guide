{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PDL_06.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buMQLouAIpMA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "K = tf.keras.backend\n",
        "Callback = tf.keras.callbacks.Callback\n",
        "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau\n",
        "\n",
        "to_categorical = tf.keras.utils.to_categorical\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = make_blobs(n_samples=3000, centers=3, n_features=2, cluster_std=2, random_state=2)"
      ],
      "metadata": {
        "id": "iOZ2b8nYJg4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.4, shuffle= True)\n",
        "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "4TT_OULQJlMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_pd = pd.DataFrame(x_train, columns=['x', 'y'])\n",
        "y_train_pd = pd.DataFrame(y_train, columns=['class'])\n",
        "\n",
        "df = pd.concat([x_train_pd, y_train_pd], axis=1)\n",
        "df[\"class\"] = df[\"class\"].astype(str)"
      ],
      "metadata": {
        "id": "kCsU6ebIJn4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(df, x=\"x\", y=\"y\", color=\"class\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4iuy_m64JroL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)"
      ],
      "metadata": {
        "id": "idER9B56Jtas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model1(learning_rates):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax', kernel_initializer='he_uniform'))\n",
        "    \n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rates)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "tNaPc7hfJwJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Model และ Plot กราฟ accuracy และ val_accuracy "
      ],
      "metadata": {
        "id": "2PKnJN_JJ3Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001]\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=4, cols=2,\n",
        "    subplot_titles=('learning_rate=1.0', 'learning_rate=0.1', 'learning_rate=0.01', 'learning_rate=0.001', 'learning_rate=0.0001', 'learning_rate=0.00001', 'learning_rate=0.000001', 'learning_rate=0.0000001')\n",
        ")\n",
        "\n",
        "for i in range(len(learning_rates)):\n",
        "    model = create_model1(learning_rates[i])\n",
        "    \n",
        "    row = (i//2)+1\n",
        "    col = (i%2)+1\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, verbose=0)\n",
        "    \n",
        "    fig.add_trace(go.Scatter(y=history.history['accuracy'], line=dict(color='blue')), row=row, col=col)\n",
        "    fig.add_trace(go.Scatter(y=history.history['val_accuracy'], line=dict(color='red')), row=row, col=col)\n",
        "    \n",
        "    fig.update_xaxes(title_text='Epochs', showgrid=False, row=row, col=col)\n",
        "    fig.update_yaxes(title_text='Accuracy', showgrid=False, row=row, col=col)\n",
        "    \n",
        "fig.update_layout(title_text='Impact of Learning Rate', height=750, showlegend=False)   "
      ],
      "metadata": {
        "id": "VWCaPwfLJzAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Momentum**"
      ],
      "metadata": {
        "id": "1nR913YuKYPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model2(momentum):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax', kernel_initializer='he_uniform'))\n",
        "    \n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=momentum)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "oV1jZxSWKEbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "momentums = [0.0, 0.5, 0.9, 0.99]\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=4, cols=2,\n",
        "    subplot_titles=('Momentum=0.0', 'Momentum=0.5', 'Momentum=0.9', 'Momentum=0.99')\n",
        ")\n",
        "\n",
        "for i in range(len(momentums)):\n",
        "    model = create_model2(momentums[i])\n",
        "    \n",
        "    row = (i//2)+1\n",
        "    col = (i%2)+1\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, verbose=0)\n",
        "    \n",
        "    fig.add_trace(go.Scatter(y=history.history['accuracy'], line=dict(color='blue')), row=row, col=col)\n",
        "    fig.add_trace(go.Scatter(y=history.history['val_accuracy'], line=dict(color='red')), row=row, col=col)\n",
        "    \n",
        "    fig.update_xaxes(title_text='Epochs', showgrid=False, row=row, col=col)\n",
        "    fig.update_yaxes(title_text='Accuracy', showgrid=False, row=row, col=col)\n",
        "    \n",
        "fig.update_layout(title_text='Impact of Momentum', height=750, showlegend=False)   \n"
      ],
      "metadata": {
        "id": "JOUYgtzSKdqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Learning Rate Decay**"
      ],
      "metadata": {
        "id": "GWtAcJ7nObvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decay_lrate(initial_lrate, decay, iteration):\n",
        "    return initial_lrate * (1.0 / (1.0 + decay * iteration))"
      ],
      "metadata": {
        "id": "2Et3hMWWOXz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "decays = [0.1, 0.01, 0.001, 0.0001]\n",
        "learning_rate = 0.01\n",
        "EPOCH = 200\n",
        "colors = ['red', 'green', 'blue', 'orange']\n",
        "\n",
        "for i, decay in enumerate(decays):\n",
        "    learning_rates = [decay_lrate(learning_rate, decay, i) for i in range(EPOCH)]\n",
        "    \n",
        "    h = go.Scatter(y=learning_rates, \n",
        "                     mode=\"lines\",\n",
        "                     line=dict(\n",
        "                         width=2,\n",
        "                         color=colors[i]),\n",
        "                     name=str(decay))\n",
        "    \n",
        "    data.append(h)\n",
        "    \n",
        "layout1 = go.Layout(title='Learning Rate',\n",
        "                   xaxis=dict(title='Epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "id": "tjrUhes-OhWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model3(decay):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax', kernel_initializer='he_uniform'))\n",
        "    \n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=0.01, decay=decay)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "UHU7NIcLOpN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('Decay=0.1', 'Decay=0.01', 'Decay=0.001', 'Decay=0.0001')\n",
        ")\n",
        "\n",
        "for i in range(len(decays)):\n",
        "    model = create_model3(decays[i])\n",
        "    \n",
        "    row = (i//2)+1\n",
        "    col = (i%2)+1\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, verbose=0)\n",
        "    \n",
        "    fig.add_trace(go.Scatter(y=history.history['accuracy'], line=dict(color='blue')), row=row, col=col)\n",
        "    fig.add_trace(go.Scatter(y=history.history['val_accuracy'], line=dict(color='red')), row=row, col=col)\n",
        "    \n",
        "    fig.update_xaxes(title_text='Epochs', showgrid=False, row=row, col=col)\n",
        "    fig.update_yaxes(title_text='Accuracy', showgrid=False, row=row, col=col)\n",
        "    \n",
        "fig.update_layout(title_text='Impact of Decay', height=750, showlegend=False)   \n"
      ],
      "metadata": {
        "id": "R7m5dgS6OtE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Drop Learning Rate on Plateau**"
      ],
      "metadata": {
        "id": "Paly6uxZPMLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LearningRateMonitor(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.learning_rates = list()\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        optimizer = self.model.optimizer\n",
        "        learning_rate = float(K.get_value(self.model.optimizer.lr))\n",
        "        self.learning_rates.append(learning_rate)"
      ],
      "metadata": {
        "id": "FkO4u3KPOxHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model4(patience):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax', kernel_initializer='he_uniform'))\n",
        "    \n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=0.01, decay=decay)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience)\n",
        "    lrm = LearningRateMonitor()\n",
        "    \n",
        "\n",
        "    return model, rlrp, lrm"
      ],
      "metadata": {
        "id": "8FiXSUPFPcbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patiences = [2, 5, 10, 15]\n",
        "\n",
        "learning_rate_list=[]\n",
        "accuracy_list=[]\n",
        "loss_list=[]\n",
        "\n",
        "for i in range(len(patiences)):\n",
        "    model, rlrp, lrm = create_model4(patiences[i])\n",
        "    \n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, verbose=0, callbacks=[rlrp, lrm])\n",
        "    lrm.learning_rates\n",
        "    \n",
        "    learning_rate_list.append(lrm.learning_rates)\n",
        "    accuracy_list.append(history.history['val_accuracy'])\n",
        "    loss_list.append(history.history['val_loss'])"
      ],
      "metadata": {
        "id": "01vqhObrPlEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patiences_plot(y, title_text):\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=('Patience=2', 'Patience=5', 'Patience=10', 'Patience=15')\n",
        "    )\n",
        "\n",
        "    for i in range(len(patiences)):\n",
        "        model = create_model4(patiences[i])\n",
        "\n",
        "        row = (i//2)+1\n",
        "        col = (i%2)+1\n",
        "        fig.add_trace(go.Scatter(y=y[i], line=dict(color='red')), row=row, col=col)\n",
        "        fig.update_xaxes(title_text='Epochs', showgrid=False, row=row, col=col)\n",
        "        fig.update_yaxes(title_text=title_text, showgrid=False, row=row, col=col)\n",
        "\n",
        "    fig.update_layout(title_text='Impact of Patience', height=750, showlegend=False)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "AVTKDCslPp7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patiences_plot(learning_rate_list, 'Learning Rate')"
      ],
      "metadata": {
        "id": "S8w64g72Puo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patiences_plot(loss_list, 'val_loss')"
      ],
      "metadata": {
        "id": "RUuZF700Py51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patiences_plot(accuracy_list, 'val_accuracy')"
      ],
      "metadata": {
        "id": "YDmvGBKwP3kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adaptive Learning Rates Gradient Descent**"
      ],
      "metadata": {
        "id": "Y20iwfoCP7Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model5(optimizer):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax', kernel_initializer='he_uniform'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "D10Su0geP-SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = ['sgd', 'rmsprop', 'adagrad', 'adam']\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('Optimizer=sgd', 'Optimizer=rmsprop', 'Optimizer=adagrad', 'Optimizer=adam')\n",
        ")\n",
        "\n",
        "for i in range(len(optimizers)):\n",
        "    model = create_model5(optimizers[i])\n",
        "    \n",
        "    row = (i//2)+1\n",
        "    col = (i%2)+1\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, verbose=0)\n",
        "    \n",
        "    fig.add_trace(go.Scatter(y=history.history['accuracy'], line=dict(color='blue')), row=row, col=col)\n",
        "    fig.add_trace(go.Scatter(y=history.history['val_accuracy'], line=dict(color='red')), row=row, col=col)\n",
        "    \n",
        "    fig.update_xaxes(title_text='Epochs', showgrid=False, row=row, col=col)\n",
        "    fig.update_yaxes(title_text='Accuracy', showgrid=False, row=row, col=col)\n",
        "    \n",
        "fig.update_layout(title_text='Impact of Optimizer', height=750, showlegend=False)   \n"
      ],
      "metadata": {
        "id": "1XZ3rPppQBev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s35gDvEqQ7Ku"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}